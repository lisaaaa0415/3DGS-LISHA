{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "edcc579a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import parameter\n",
    "import argparse\n",
    "import sys\n",
    "import torch\n",
    "import os\n",
    "from plyfile import PlyData\n",
    "import numpy as np\n",
    "import cv2\n",
    "from utils.camera_utils import focal2fov\n",
    "\n",
    "from utils.colmap_utils import (\n",
    "    read_extrinsics_binary, \n",
    "    read_intrinsics_binary, \n",
    "    read_points3D_binary, \n",
    "    read_points3D_text,\n",
    "    qvec2rotmat\n",
    ")\n",
    "\n",
    "def ParamReader(argv=None):\n",
    "    if argv is None:\n",
    "        argv = sys.argv[1:]\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    data = parameter.data\n",
    "    for key, value in data.items():\n",
    "        parser.add_argument(f'--{key}', default=value, help=f'{key} parameter')\n",
    "    \n",
    "    parser.add_argument(\"--detect_anomaly\", action=\"store_true\", default=False)\n",
    "    parser.add_argument(\"--test_iterations\", nargs=\"+\", type=int, default=[100, 1_000, 7_000, 30_000])\n",
    "    parser.add_argument(\"--save_iterations\", nargs=\"+\", type=int, default=[100, 1_000, 7_000, 30_000])    \n",
    "    parser.add_argument(\"--checkpoint_iterations\", nargs=\"+\", type=int, default=[100, 1_000, 7_000, 30_000])\n",
    "    parser.add_argument(\"--start_checkpoint\", type=str, default=None)\n",
    "    \n",
    "    args = parser.parse_args(argv)\n",
    "    return args\n",
    "\n",
    "class PointClond:\n",
    "    def __init__(self, positions, colors, normals):\n",
    "        self.positions = positions\n",
    "        self.colors = colors\n",
    "        self.normals = normals\n",
    "\n",
    "class ImageInfo:\n",
    "    def __init__(self,image_name, image_path, image, image_width, image_height, R, T, fov_x, fov_y, device):\n",
    "        self.image_name=image_name\n",
    "        self.image_path=image_path\n",
    "        self.image = torch.from_numpy(image).to(device)\n",
    "        self.image_width=image_width\n",
    "        self.image_height=image_height\n",
    "        self.R=R\n",
    "        self.T=T\n",
    "        self.fov_x=fov_x\n",
    "        self.fov_y=fov_y\n",
    "        self.zfar = 100.0  # 远平面\n",
    "        self.znear = 0.01  # 近平面\n",
    "        # 计算相机矩阵并移动到指定设备\n",
    "        self.viewMatrix = self.getViewMatrix(self.R, self.T).to(device)\n",
    "        # 计算投影矩阵并移动到指定设备\n",
    "        self.projMatrix = self.getProjMatrix(self.znear, self.zfar, self.fov_x, self.fov_y).to(device)\n",
    "        self.viewProjMatrix = self.viewMatrix @ self.projMatrix\n",
    "        #计算相机中心，逆相机矩阵的前三行第三列中\n",
    "        self.cameraCenter = torch.inverse(self.viewMatrix)[:3, 3]\n",
    "    def getViewMatrix(self, R, T):\n",
    "        viewMatrix=torch.zeros((4, 4), dtype=torch.float32)\n",
    "        viewMatrix[3, 3] = 1.0\n",
    "        R=torch.tensor(R, dtype=torch.float32)\n",
    "        viewMatrix[:3, :3] = R\n",
    "        T=torch.tensor(T, dtype=torch.float32)\n",
    "        viewMatrix[:3, 3] = T\n",
    "        return viewMatrix\n",
    "    \n",
    "    def getProjMatrix(self,znear, zfar, fov_x,fov_y):\n",
    "        #计算视场角正切值的一半\n",
    "        tan_fov_y = np.tan((fov_y / 2))\n",
    "        tan_fov_x = np.tan((fov_x / 2))\n",
    "        projMatrix=torch.zeros((4, 4), dtype=torch.float32)\n",
    "        projMatrix[3,2]=1.0\n",
    "        \n",
    "        #left、right,bottom,top 是近平面的边界\n",
    "        top = tan_fov_y * znear\n",
    "        bottom = -top\n",
    "        right = tan_fov_x * znear\n",
    "        left = -right\n",
    "        projMatrix[0,0]=2*znear/(right-left)\n",
    "        projMatrix[1,1]=2*znear/(top-bottom)\n",
    "        projMatrix[2,2]=(zfar+znear)/(zfar-znear)\n",
    "        projMatrix[2,3]=2*znear*zfar/(znear-zfar)\n",
    "        \n",
    "        return projMatrix\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "class GSDataLoader:\n",
    "    def __init__(self,data_path,reading_dir,device):\n",
    "        self.data_path=data_path\n",
    "        self.reading_dir=reading_dir\n",
    "        self.device=device\n",
    "        self.cameras=[]#相机\n",
    "        self.points={}#点云\n",
    "        self.data_path=r'D:\\CODE_ALL\\3DGS-LISHA\\data' \n",
    "        self.loadColmap(reading_dir)\n",
    "    \n",
    "    def loadColmap(self,reading_dir):\n",
    "        \n",
    "        cameras_intrinsic_path = os.path.join( self.data_path, \"sparse\", \"0\", \"cameras.bin\")\n",
    "        cameras_extrinsic_path= os.path.join( self.data_path, \"sparse\", \"0\", \"images.bin\")\n",
    "        #读取相机的外参\n",
    "        cam_extrinsics = read_extrinsics_binary(cameras_extrinsic_path)\n",
    "        #读取相机的内参\n",
    "        cam_intrinsics = read_intrinsics_binary(cameras_intrinsic_path)\n",
    "        #print('外参',cam_extrinsics)\n",
    "        #print('内参',cam_intrinsics)\n",
    "        \n",
    "        #点云\n",
    "        ply_path = os.path.join(self.data_path,  \"sparse\", \"0\", \"points3D.ply\")\n",
    "        plydata = PlyData.read(ply_path)\n",
    "        # 提取顶点数据\n",
    "        vertices = plydata['vertex']\n",
    "        x = vertices['x']\n",
    "        y = vertices['y']\n",
    "        z = vertices['z']\n",
    "        positions = np.vstack([x,y, z]).T\n",
    "        #print( positions)\n",
    "        \n",
    "        \n",
    "        # 提取颜色数据\n",
    "        red = vertices['red']\n",
    "        green = vertices['green']\n",
    "        blue = vertices['blue']\n",
    "        colors = np.vstack([red,green, blue]).T/255.0\n",
    "        #print( colors)\n",
    "        \n",
    "        # 提取法线数据\n",
    "        nx = vertices['nx']\n",
    "        ny = vertices['ny']\n",
    "        nz = vertices['nz']\n",
    "        normals = np.vstack([nx,ny, nz]).T\n",
    "        #print( normals)\n",
    "        self.points=PointClond(positions,colors,normals)\n",
    "        \n",
    "        # 读取图片\n",
    "        # 将图像文件夹路径与数据根路径结合，形成完整的图像文件夹路径\n",
    "        images_folder=os.path.join(self.data_path, reading_dir)\n",
    "        for idx, key in enumerate(cam_extrinsics):\n",
    "            #外参\n",
    "            extr=cam_extrinsics[key]\n",
    "            #内参\n",
    "            intr=cam_intrinsics[extr.camera_id]\n",
    "             # 获取图像的高度和宽度\n",
    "            image_height = intr.height\n",
    "            image_width = intr.width\n",
    "            #id\n",
    "            uid=intr.id\n",
    "            # 将四元数转换为旋转矩阵，然后对旋转矩阵进行转置\n",
    "            R = qvec2rotmat(extr.qvec) \n",
    "            #print(R)\n",
    "            # 获取平移向量\n",
    "            T = extr.tvec  \n",
    "            # 获取图像路径并读取图像\n",
    "            \n",
    "            # 处理不同的相机模型\n",
    "            # 判断相机模型是否为简单针孔相机\n",
    "            if intr.model==\"SIMPLE_PINHOLE\":\n",
    "                #焦距\n",
    "                focal_length_x = intr.params[0]\n",
    "                 # 通过焦距和height计算垂直方向视场角（摄像机在垂直方向上可见的视场范围的角度大小）\n",
    "                fov_y= focal2fov(focal_length_x, image_height)\n",
    "                 # 计算水平方向视场角\n",
    "                fov_x = focal2fov(focal_length_x, image_width)\n",
    "            elif intr.model==\"PINHOLE\":\n",
    "                focal_length_x = intr.params[0]\n",
    "                focal_length_y = intr.params[1]\n",
    "                fov_y= focal2fov(focal_length_y, image_height)\n",
    "                fov_x = focal2fov(focal_length_x, image_width)\n",
    "            else:\n",
    "                assert False, \"Colmap camera model not handled: only undistorted datasets (PINHOLE or SIMPLE_PINHOLE cameras) supported!\"\n",
    "            image_path = os.path.join(images_folder, extr.name)\n",
    "            #读取图像\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(f\"Error loading image: {image_path}\")\n",
    "                continue\n",
    "            #print(image_path)\n",
    "            # 将图像颜色空间从BGR转换为RGB\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image_info=ImageInfo(image_name=extr.name, \n",
    "                image_path=image_path, \n",
    "                image=image, \n",
    "                image_width=image_width, \n",
    "                image_height=image_height, \n",
    "                R=R, T=T, \n",
    "                fov_x=fov_x,\n",
    "                fov_y=fov_y, \n",
    "                device=self.device)\n",
    "            self.cameras.append(image_info)\n",
    "               \n",
    "    \n",
    "# 测试\n",
    "argv = ['--detect_anomaly', '--test_iterations', '100', '2000', '--save_iterations', '100', '2000']\n",
    "args=ParamReader(argv)\n",
    "device = torch.device('cpu')\n",
    "data = GSDataLoader(args.source_path, args.images, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b404db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfb3002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d90d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9e9eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
